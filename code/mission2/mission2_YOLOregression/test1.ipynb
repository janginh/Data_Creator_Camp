{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38cbebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d851f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 1. 데이터 준비 함수\n",
    "# =====================================================\n",
    "def pixel_distance(p1, p2):\n",
    "    return math.sqrt((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)\n",
    "\n",
    "def extract_features(json_path, img_path, model):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    features, labels = [], []\n",
    "    # 메타데이터\n",
    "    for _, v in data.items():\n",
    "        res   = float(v[\"file_attributes\"][\"img_resolution\"])\n",
    "        roll  = float(v[\"file_attributes\"][\"img_roll_tilt\"])\n",
    "        pitch = float(v[\"file_attributes\"][\"img_pitch_tilt\"])\n",
    "        h     = float(v[\"file_attributes\"][\"img_height\"])\n",
    "        w     = float(v[\"file_attributes\"][\"img_width\"])\n",
    "\n",
    "        # YOLO 예측\n",
    "        results = model.predict(img_path, verbose=False)\n",
    "        kpts_all = results[0].keypoints.xy.cpu().numpy()  # (N, K, 2)\n",
    "\n",
    "        for i, region in enumerate(v[\"regions\"]):\n",
    "            xs = region[\"shape_attributes\"][\"all_points_x\"]\n",
    "            ys = region[\"shape_attributes\"][\"all_points_y\"]\n",
    "            h_true = float(region[\"region_attributes\"][\"chi_height_m\"])\n",
    "\n",
    "            if kpts_all.shape[0] > i:  # YOLO가 해당 굴뚝을 탐지했다고 가정\n",
    "                kp = kpts_all[i]\n",
    "                if kp.shape[0] >= 2:\n",
    "                    x1, y1 = kp[0][0], kp[0][1]\n",
    "                    x2, y2 = kp[1][0], kp[1][1]\n",
    "                    pred_pixel_len = pixel_distance((x1,y1),(x2,y2))\n",
    "\n",
    "                    # feature = [pred_pixel_len, res, roll, pitch]\n",
    "                    features.append([pred_pixel_len, res, roll, pitch])\n",
    "                    labels.append(h_true)\n",
    "\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38addf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 2. Dataset 클래스\n",
    "# =====================================================\n",
    "class ChimneyDataset(Dataset):\n",
    "    def __init__(self, img_dir, json_dir, model):\n",
    "        self.X, self.y = [], []\n",
    "        for img_name in os.listdir(img_dir):\n",
    "            if not img_name.endswith(\".jpg\"):\n",
    "                continue\n",
    "            img_path = os.path.join(img_dir, img_name)\n",
    "            json_path = os.path.join(json_dir, img_name.replace(\".jpg\",\".json\"))\n",
    "            feats, labels = extract_features(json_path, img_path, model)\n",
    "            self.X.extend(feats)\n",
    "            self.y.extend(labels)\n",
    "\n",
    "        self.X = torch.tensor(self.X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(self.y, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f06d683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 3. 모델 정의 (MLP)\n",
    "# =====================================================\n",
    "class HeightRegressor(nn.Module):\n",
    "    def __init__(self, in_dim=4, hidden=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6471fbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 6873.4937\n",
      "Epoch 2/30, Loss: 1369.9614\n",
      "Epoch 3/30, Loss: 1337.2332\n",
      "Epoch 4/30, Loss: 1337.2065\n",
      "Epoch 5/30, Loss: 1296.4686\n",
      "Epoch 6/30, Loss: 1271.9895\n",
      "Epoch 7/30, Loss: 1277.1972\n",
      "Epoch 8/30, Loss: 1255.6275\n",
      "Epoch 9/30, Loss: 1240.7415\n",
      "Epoch 10/30, Loss: 1238.1536\n",
      "Epoch 11/30, Loss: 1222.3348\n",
      "Epoch 12/30, Loss: 1232.2620\n",
      "Epoch 13/30, Loss: 1264.3118\n",
      "Epoch 14/30, Loss: 1212.1470\n",
      "Epoch 15/30, Loss: 1172.3432\n",
      "Epoch 16/30, Loss: 1179.6570\n",
      "Epoch 17/30, Loss: 1169.5710\n",
      "Epoch 18/30, Loss: 1159.9460\n",
      "Epoch 19/30, Loss: 1156.7954\n",
      "Epoch 20/30, Loss: 1156.3407\n",
      "Epoch 21/30, Loss: 1138.8713\n",
      "Epoch 22/30, Loss: 1131.7105\n",
      "Epoch 23/30, Loss: 1114.9402\n",
      "Epoch 24/30, Loss: 1114.0730\n",
      "Epoch 25/30, Loss: 1097.4155\n",
      "Epoch 26/30, Loss: 1109.2543\n",
      "Epoch 27/30, Loss: 1092.4640\n",
      "Epoch 28/30, Loss: 1071.5891\n",
      "Epoch 29/30, Loss: 1056.8135\n",
      "Epoch 30/30, Loss: 1038.8655\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 4. 학습 루프\n",
    "# =====================================================\n",
    "VAL_IMG_DIR = \"../valid/images\"\n",
    "VAL_JSON_DIR = \"../valid/json\"\n",
    "\n",
    "# best.pt 불러오기\n",
    "model_yolo = YOLO(\"C:/Users/USER/Desktop/personal/dcc/mission2/mission2_yolo2/runs/chimney_pose/weights/best.pt\")\n",
    "\n",
    "dataset = ChimneyDataset(VAL_IMG_DIR, VAL_JSON_DIR, model_yolo)\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "regressor = HeightRegressor().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(regressor.parameters(), lr=1e-3)\n",
    "\n",
    "EPOCHS = 30\n",
    "for epoch in range(EPOCHS):\n",
    "    regressor.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        pred = regressor(X_batch)\n",
    "        loss = criterion(pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86898ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 RMSE: 31.909612794138933\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 5. RMSE 평가\n",
    "# =====================================================\n",
    "regressor.eval()\n",
    "with torch.no_grad():\n",
    "    preds = regressor(dataset.X.to(device)).cpu().numpy().flatten()\n",
    "    y_true = dataset.y.numpy().flatten()\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, preds))\n",
    "\n",
    "print(\"최종 RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e7b2b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =====================================================\n",
    "# 50개 랜덤 샘플 시각화 및 저장\n",
    "# =====================================================\n",
    "def visualize_batch(img_dir, json_dir, model_yolo, regressor, save_dir=\"vis_results\", device=\"cpu\", num_samples=50):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    img_files = [f for f in os.listdir(img_dir) if f.endswith(\".jpg\")]\n",
    "    random.shuffle(img_files)\n",
    "    img_files = img_files[:num_samples]\n",
    "\n",
    "    for idx, img_name in enumerate(img_files):\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        json_path = os.path.join(json_dir, img_name.replace(\".jpg\",\".json\"))\n",
    "\n",
    "        # --- GT 불러오기 ---\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        h_true = float(data[list(data.keys())[0]][\"regions\"][0][\"region_attributes\"][\"chi_height_m\"])\n",
    "\n",
    "        # --- YOLO 예측 ---\n",
    "        results = model_yolo.predict(img_path, verbose=False)\n",
    "        if len(results[0].keypoints.xy) == 0:\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        kpts = results[0].keypoints.xy.cpu().numpy()[0]  # 첫 번째 객체만 예시\n",
    "        x1, y1 = int(kpts[0][0]), int(kpts[0][1])\n",
    "        x2, y2 = int(kpts[1][0]), int(kpts[1][1])\n",
    "\n",
    "        # --- 메타데이터 로드 ---\n",
    "        v = list(data.values())[0]\n",
    "        res   = float(v[\"file_attributes\"][\"img_resolution\"])\n",
    "        roll  = float(v[\"file_attributes\"][\"img_roll_tilt\"])\n",
    "        pitch = float(v[\"file_attributes\"][\"img_pitch_tilt\"])\n",
    "\n",
    "        # --- 회귀 예측 ---\n",
    "        pred_pixel_len = math.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "        feat = torch.tensor([[pred_pixel_len, res, roll, pitch]], dtype=torch.float32).to(device)\n",
    "        h_pred = regressor(feat).item()\n",
    "\n",
    "        # --- 시각화 ---\n",
    "        cv2.circle(img, (x1,y1), 5, (0,0,255), -1)\n",
    "        cv2.circle(img, (x2,y2), 5, (0,255,0), -1)\n",
    "        cv2.line(img, (x1,y1), (x2,y2), (255,0,0), 2)\n",
    "\n",
    "        text = f\"Pred: {h_pred:.2f} m | GT: {h_true:.2f} m\"\n",
    "        cv2.putText(img, text, (30,30), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.8, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # 저장\n",
    "        save_path = os.path.join(save_dir, f\"vis_{idx}_{img_name}\")\n",
    "        cv2.imwrite(save_path, img)\n",
    "\n",
    "    print(f\"[완료] {len(img_files)}개 샘플 시각화 → {save_dir} 폴더에 저장됨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "211c8903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[완료] 50개 샘플 시각화 → vis_results 폴더에 저장됨\n"
     ]
    }
   ],
   "source": [
    "visualize_batch(\n",
    "    img_dir=\"../valid/images\",\n",
    "    json_dir=\"../valid/json\",\n",
    "    model_yolo=model_yolo,\n",
    "    regressor=regressor,\n",
    "    save_dir=\"vis_results\",\n",
    "    device=device,\n",
    "    num_samples=50\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
